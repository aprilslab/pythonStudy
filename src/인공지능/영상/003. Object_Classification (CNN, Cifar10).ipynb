{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWdJrbNRC-W4"
   },
   "source": [
    "## Object Classification\n",
    "\n",
    "* Cifar10 데이터셋 사용\n",
    "* CNN으로 Object Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzE79X0mMszk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIDtRIduMx3Z"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' #GPU 사용이 가능하다면 GPU를 사용하고 아니면 CPU를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XDOJBRNNCZM"
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001 #학습율, 하이퍼파라미터로 학습하는 것이 아니고 입력하는 값\n",
    "epochs = 10            # 전체 데이터를 1번 학습한다.\n",
    "batch_size = 100      # 데이터 학습시 데이터의 단위(100개 씩 학습함)\n",
    "drop_out = 0.25        # 1 epoch 학습할 때 0.25프로 연결을 끊는다. 정규화하는 방법 중의 하나이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CR7RpRmgNFVe",
    "outputId": "3a180ff5-fe52-4cf1-cc55-2471d24f18ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "training_data = datasets.CIFAR10(root='CIFAR_data/', #데이터의 위치\n",
    "                                 train = True,\n",
    "                                 transform=transform, #이미지를 tensor에 맞게 조정\n",
    "                                 download=True) #데이터를 root위치에 다운로드한다. 이미 존재하는 경우 다시 다운하지 않는다.\n",
    "\n",
    "test_data = datasets.CIFAR10(root='CIFAR_data/',\n",
    "                             train=False, \n",
    "                             transform=transform,\n",
    "                             download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nR740IaNJ6r"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovzjwzbiXg7g"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #첫번째 layer 생성\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size = 5, stride =1, padding = 1), # 입력 채널 개수(컬러이미지), 출력 채널 개수, 건너 띄기 없음, same padding\n",
    "            nn.ReLU(), #activation function. (비선형함수, 음수는 0으로 바꾼다)\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2), #32x32 -> 16x16x32로 사이즈가 줄어든다\n",
    "            nn.Dropout(drop_out)) \n",
    "        \n",
    "        #두 번째 layer 생성\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride =1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2), #16x16x64 -> 8x8x64로 사이즈가 줄어든다\n",
    "            nn.Dropout(drop_out)) \n",
    "\n",
    "        #세 번째 layer 생성\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride =1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2), #8x8x64 -> 4x4x128로 사이즈가 줄어든다\n",
    "            nn.Dropout(drop_out)) \n",
    "\n",
    "        #네 번째 layer 생성\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride =1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2), #4x4x128 -> 2x2x256로 사이즈가 줄어든다\n",
    "            nn.Dropout(drop_out)) \n",
    "\n",
    "        #fully connected layer 생성\n",
    "        self.fc = nn.Linear(2 * 2 * 256, 10, bias = True) # 행렬 데이터를 벡터로 바꿔를 입력하여 10개(0~9)로 출력함\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "   \n",
    "   #모델 설계 후 데이터셋이 layer들을 통과할 수 있게 함.\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbD5mN7he2WE"
   },
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kqhcm_mNggaa"
   },
   "outputs": [],
   "source": [
    "#cost & loss 명시하기 & optimizer\n",
    "# pytorch는 softmax가 포함이 되어 있기 때문에 생략\n",
    "criterion = nn.CrossEntropyLoss().to(device)    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #gradient descent할 때 adam 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cVG4rycgrYL",
    "outputId": "ea354e81-7b71-467a-eb73-2f3b006c2606"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Learning started. It takes sometime.\n",
      "[Epoch:    1] cost = 1.72557235\n",
      "[Epoch:    2] cost = 1.39580989\n",
      "[Epoch:    3] cost = 1.24194062\n",
      "[Epoch:    4] cost = 1.1490159\n",
      "[Epoch:    5] cost = 1.06548655\n",
      "[Epoch:    6] cost = 1.00073266\n",
      "[Epoch:    7] cost = 0.961116552\n",
      "[Epoch:    8] cost = 0.924154758\n",
      "[Epoch:    9] cost = 0.897860289\n",
      "[Epoch:   10] cost = 0.870349586\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_dataloader)\n",
    "model.train()\n",
    "print(total_batch) # total batch값 500출력. (5만개의 데이터가 batch_size인 100으로 나뉜 값)\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in train_dataloader:\n",
    "        X = X.to(device) # batch_size(100), 채널(3= 컬러), 32 X 32 사이즈의 이미지 데이터를 입력함\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()            # optimizer 변수에 포함시킨 매개 변수(weight)들의 기울기(Gradient)를 0으로 초기화\n",
    "        hypothesis = model(X)            # 가설 설정\n",
    "        cost = criterion(hypothesis, Y)  # 비용 설정\n",
    "        cost.backward()                  # 역전파\n",
    "        optimizer.step()                 # 학습을 통해 계산한 weight, bias, gradient를 최적화함수(optimizer)에에 반영\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcQgokp-rU4-",
    "outputId": "b98d2cd9-e617-4d22-88d2-887cb9afe9af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): #gradient 비활성화\n",
    "    model.eval()\n",
    "    for X_test, Y_test in test_dataloader:\n",
    "        outputs = model(X_test.float().to(device))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += Y_test.size(0)\n",
    "        correct += (predicted == Y_test.to(device)).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqEnHP76hE_i",
    "outputId": "e53a76fe-2b07-4ceb-b71d-34e50dbbd9ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: plane is 69.6 %\n",
      "Accuracy for class: car   is 83.5 %\n",
      "Accuracy for class: bird  is 58.6 %\n",
      "Accuracy for class: cat   is 46.4 %\n",
      "Accuracy for class: deer  is 67.8 %\n",
      "Accuracy for class: dog   is 69.4 %\n",
      "Accuracy for class: frog  is 86.0 %\n",
      "Accuracy for class: horse is 69.6 %\n",
      "Accuracy for class: ship  is 90.8 %\n",
      "Accuracy for class: truck is 78.8 %\n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "with torch.no_grad(): #gradient 비활성화\n",
    "    model.eval()\n",
    "    for X_test, Y_test in test_dataloader:\n",
    "        outputs = model(X_test.float().to(device))\n",
    "        _, predictions = torch.max(outputs.data, 1)\n",
    "        for label, pred in zip(Y_test.to(device), predictions):\n",
    "          if label == pred:\n",
    "              correct_pred[classes[label]] += 1\n",
    "          total_pred[classes[label]] += 1\n",
    "\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * correct_count / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHxXZQe3DlIj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
